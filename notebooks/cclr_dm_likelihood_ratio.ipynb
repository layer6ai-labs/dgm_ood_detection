{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3/5: 100%|██████████| 4/4 [00:01<00:00,  3.36it/s]\n",
      "4/6: 100%|██████████| 5/5 [00:02<00:00,  2.36it/s]\n",
      "3/5: 100%|██████████| 4/4 [00:01<00:00,  3.30it/s]\n",
      "4/6: 100%|██████████| 5/5 [00:02<00:00,  2.27it/s]\n",
      "3/5: 100%|██████████| 4/4 [00:01<00:00,  3.35it/s]\n",
      "4/6: 100%|██████████| 5/5 [00:02<00:00,  2.34it/s]\n",
      "3/5: 100%|██████████| 4/4 [00:01<00:00,  3.39it/s]\n",
      "4/6: 100%|██████████| 5/5 [00:02<00:00,  2.32it/s]\n",
      "3/5: 100%|██████████| 4/4 [00:01<00:00,  3.22it/s]\n",
      "4/6: 100%|██████████| 5/5 [00:02<00:00,  2.27it/s]\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "from utils import parse_table, read_csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pretty import plot_kde, ColorTheme\n",
    "\n",
    "\n",
    "\n",
    "print_mapping = {\n",
    "    'fashion-mnist': 'FMNIST',\n",
    "    'mnist': 'MNIST',\n",
    "    'emnist': 'EMNIST',\n",
    "    'omniglot': 'Omniglot',\n",
    "    'celeba-small': 'CelebA',\n",
    "    'svhn': 'SVHN',\n",
    "    'cifar10': 'CIFAR10',\n",
    "    'cifar100': 'CIFAR100',\n",
    "    'tiny-imagenet': 'Tiny',\n",
    "}\n",
    "\n",
    "cclr_hps = ['0.1', '0.25', '0.33', '0.5', '0.66']\n",
    "all_tasks = {}\n",
    "\n",
    "for hp in cclr_hps:\n",
    "    df_grayscale = read_csv(f'grayscale_cclr_{hp}.csv')\n",
    "    df_rgb = read_csv(f'rgb_cclr_{hp}.csv')\n",
    "    all_grayscale_tasks = parse_table(df_grayscale)\n",
    "    all_rgb_tasks = parse_table(df_rgb)\n",
    "    all_tasks_internal = {\n",
    "        'grayscale': all_grayscale_tasks,\n",
    "        'rgb': all_rgb_tasks,\n",
    "    }\n",
    "\n",
    "    all_pairs = []\n",
    "    for tp in all_tasks_internal.keys():\n",
    "        for in_distr in all_tasks_internal[tp].keys():\n",
    "                for ood in all_tasks_internal[tp].keys():\n",
    "                    if in_distr != ood:\n",
    "                        all_pairs.append((in_distr, ood, tp))\n",
    "    all_tasks[hp] = all_tasks_internal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['grayscale', 'rgb'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tasks['0.1'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_scores(in_distr, ood, type, all_tasks): \n",
    "    global score_in, score_ood, score_generated\n",
    "    in_vs_out = all_tasks[type][in_distr][ood]\n",
    "    # find the column that starts with 'Cclr with frac'\n",
    "    col = [c for c in in_vs_out.columns if c.startswith('Cclr with frac')][0]\n",
    "    score_generated = in_vs_out[in_vs_out['name'] == 'generated'][col].values\n",
    "    score_in = in_vs_out[in_vs_out['name'] == 'test'][col].values\n",
    "    score_ood = in_vs_out[in_vs_out['name'] == 'ood'][col].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMNIST vs FMNIST\n",
      "best AUC of test-vs-out 0.238\n",
      "best AUC of generated-vs-out 0.997\n",
      "----\n",
      "EMNIST vs Omniglot\n",
      "best AUC of test-vs-out 0.285\n",
      "best AUC of generated-vs-out 0.997\n",
      "----\n",
      "EMNIST vs MNIST\n",
      "best AUC of test-vs-out 0.436\n",
      "best AUC of generated-vs-out 0.998\n",
      "----\n",
      "FMNIST vs EMNIST\n",
      "best AUC of test-vs-out 0.576\n",
      "best AUC of generated-vs-out 0.997\n",
      "----\n",
      "FMNIST vs Omniglot\n",
      "best AUC of test-vs-out 0.388\n",
      "best AUC of generated-vs-out 0.996\n",
      "----\n",
      "FMNIST vs MNIST\n",
      "best AUC of test-vs-out 0.781\n",
      "best AUC of generated-vs-out 0.998\n",
      "----\n",
      "Omniglot vs EMNIST\n",
      "best AUC of test-vs-out 0.263\n",
      "best AUC of generated-vs-out 0.996\n",
      "----\n",
      "Omniglot vs FMNIST\n",
      "best AUC of test-vs-out 0.169\n",
      "best AUC of generated-vs-out 0.995\n",
      "----\n",
      "Omniglot vs MNIST\n",
      "best AUC of test-vs-out 0.338\n",
      "best AUC of generated-vs-out 0.997\n",
      "----\n",
      "MNIST vs EMNIST\n",
      "best AUC of test-vs-out 0.391\n",
      "best AUC of generated-vs-out 0.998\n",
      "----\n",
      "MNIST vs FMNIST\n",
      "best AUC of test-vs-out 0.224\n",
      "best AUC of generated-vs-out 0.996\n",
      "----\n",
      "MNIST vs Omniglot\n",
      "best AUC of test-vs-out 0.296\n",
      "best AUC of generated-vs-out 0.997\n",
      "----\n",
      "CIFAR10 vs SVHN\n",
      "best AUC of test-vs-out 0.829\n",
      "best AUC of generated-vs-out 0.959\n",
      "----\n",
      "CIFAR10 vs CelebA\n",
      "best AUC of test-vs-out 0.553\n",
      "best AUC of generated-vs-out 0.835\n",
      "----\n",
      "CIFAR10 vs Tiny\n",
      "best AUC of test-vs-out 0.485\n",
      "best AUC of generated-vs-out 0.744\n",
      "----\n",
      "CIFAR10 vs CIFAR100\n",
      "best AUC of test-vs-out 0.498\n",
      "best AUC of generated-vs-out 0.764\n",
      "----\n",
      "SVHN vs CIFAR10\n",
      "best AUC of test-vs-out 0.326\n",
      "best AUC of generated-vs-out 0.441\n",
      "----\n",
      "SVHN vs CelebA\n",
      "best AUC of test-vs-out 0.357\n",
      "best AUC of generated-vs-out 0.474\n",
      "----\n",
      "SVHN vs Tiny\n",
      "best AUC of test-vs-out 0.318\n",
      "best AUC of generated-vs-out 0.435\n",
      "----\n",
      "SVHN vs CIFAR100\n",
      "best AUC of test-vs-out 0.325\n",
      "best AUC of generated-vs-out 0.439\n",
      "----\n",
      "CelebA vs CIFAR10\n",
      "best AUC of test-vs-out 0.403\n",
      "best AUC of generated-vs-out 0.717\n",
      "----\n",
      "CelebA vs SVHN\n",
      "best AUC of test-vs-out 0.650\n",
      "best AUC of generated-vs-out 0.935\n",
      "----\n",
      "CelebA vs Tiny\n",
      "best AUC of test-vs-out 0.401\n",
      "best AUC of generated-vs-out 0.717\n",
      "----\n",
      "CelebA vs CIFAR100\n",
      "best AUC of test-vs-out 0.402\n",
      "best AUC of generated-vs-out 0.711\n",
      "----\n",
      "Tiny vs CIFAR10\n",
      "best AUC of test-vs-out 0.478\n",
      "best AUC of generated-vs-out 0.741\n",
      "----\n",
      "Tiny vs SVHN\n",
      "best AUC of test-vs-out 0.818\n",
      "best AUC of generated-vs-out 0.966\n",
      "----\n",
      "Tiny vs CelebA\n",
      "best AUC of test-vs-out 0.498\n",
      "best AUC of generated-vs-out 0.813\n",
      "----\n",
      "Tiny vs CIFAR100\n",
      "best AUC of test-vs-out 0.478\n",
      "best AUC of generated-vs-out 0.737\n",
      "----\n",
      "CIFAR100 vs CIFAR10\n",
      "best AUC of test-vs-out 0.498\n",
      "best AUC of generated-vs-out 0.817\n",
      "----\n",
      "CIFAR100 vs SVHN\n",
      "best AUC of test-vs-out 0.827\n",
      "best AUC of generated-vs-out 0.969\n",
      "----\n",
      "CIFAR100 vs CelebA\n",
      "best AUC of test-vs-out 0.561\n",
      "best AUC of generated-vs-out 0.875\n",
      "----\n",
      "CIFAR100 vs Tiny\n",
      "best AUC of test-vs-out 0.485\n",
      "best AUC of generated-vs-out 0.794\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "from roc_analysis import get_roc_graph, get_convex_hull, get_auc\n",
    "from tqdm import tqdm\n",
    "\n",
    "for in_distr, ood, tp in all_pairs:\n",
    "    print(f'{print_mapping[in_distr]} vs {print_mapping[ood]}')\n",
    "    max_auc = -1.\n",
    "    max_auc_generated = -1.\n",
    "    for hp in cclr_hps:\n",
    "        get_scores(in_distr, ood, tp, all_tasks[hp])\n",
    "        x_naive, y_naive = get_roc_graph(\n",
    "            pos_x = score_in,\n",
    "            neg_x = score_ood,\n",
    "            verbose=0,\n",
    "        )\n",
    "        x_curve, y_curve = get_convex_hull(x_naive, y_naive)\n",
    "        test_vs_ood_auc = get_auc(x_curve, y_curve)\n",
    "        max_auc = max(max_auc, test_vs_ood_auc)\n",
    "        \n",
    "        x_naive, y_naive = get_roc_graph(\n",
    "            pos_x = score_generated,\n",
    "            neg_x = score_ood,\n",
    "            verbose=0,\n",
    "        )\n",
    "        x_curve, y_curve = get_convex_hull(x_naive, y_naive)\n",
    "        generated_vs_ood_auc = get_auc(x_curve, y_curve)\n",
    "        max_auc_generated = max(max_auc_generated, generated_vs_ood_auc)\n",
    "    print(\"best AUC of test-vs-out\", \"{:.3f}\".format(max_auc))\n",
    "    print(\"best AUC of generated-vs-out\", \"{:.3f}\".format(max_auc_generated))\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oslow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
